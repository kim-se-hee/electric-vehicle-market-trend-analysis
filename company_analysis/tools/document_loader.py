"""
Document Loader
ê¸°ì—… ë¬¸ì„œ ìˆ˜ì§‘ ë„êµ¬
"""
from typing import List
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from common.config.settings import settings
import logging
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class DocumentLoader:
    """ê¸°ì—… ê´€ë ¨ ë¬¸ì„œ ìˆ˜ì§‘"""
    
    def __init__(self):
        self.logger = logging.getLogger("DocumentLoader")
        self.search_tool = TavilySearchResults(
            max_results=settings.TAVILY_MAX_RESULTS,
            api_key=settings.TAVILY_API_KEY
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
    
    def load_company_documents(self, companies: List[str]) -> List[Document]:
        """
        ê¸°ì—…ë“¤ì˜ ë¬¸ì„œ ìˆ˜ì§‘
        
        Args:
            companies: ê¸°ì—…ëª… ë¦¬ìŠ¤íŠ¸
            
        Returns:
            Document ë¦¬ìŠ¤íŠ¸
        """
        all_documents = []
        
        for company in companies:
            self.logger.info(f"ğŸ“„ {company} ë¬¸ì„œ ìˆ˜ì§‘ ì¤‘...")
            docs = self._load_single_company(company)
            all_documents.extend(docs)
            self.logger.info(f"  â†’ {len(docs)}ê°œ ë¬¸ì„œ ìˆ˜ì§‘")
        
        return all_documents
    
    def _load_single_company(self, company: str) -> List[Document]:
        """ë‹¨ì¼ ê¸°ì—… ë¬¸ì„œ ìˆ˜ì§‘"""
        documents = []
        
        # 1. ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ URL ì°¾ê¸°
        search_queries = [
            f"{company} ì „ê¸°ì°¨ ì‚¬ì—… ì „ëµ 2025",
            f"{company} ë°°í„°ë¦¬ ê¸°ìˆ  ì œí’ˆ",
            f"{company} IR ìë£Œ ì‹¤ì ",
            f"{company} íŒŒíŠ¸ë„ˆì‹­ í˜‘ë ¥"
        ]
        
        urls = set()
        for query in search_queries:
            try:
                results = self.search_tool.invoke({"query": query})
                for result in results:
                    if isinstance(result, dict) and "url" in result:
                        urls.add(result["url"])
            except Exception as e:
                self.logger.warning(f"ê²€ìƒ‰ ì‹¤íŒ¨ ({query}): {e}")
        
        # 2. URLì—ì„œ ë¬¸ì„œ ë¡œë“œ
        for url in list(urls)[:10]:  # ìµœëŒ€ 10ê°œ URL
            try:
                loader = WebBaseLoader(url)
                docs = loader.load()
                
                # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                for doc in docs:
                    doc.metadata["company"] = company
                    doc.metadata["source_url"] = url
                
                documents.extend(docs)
                
            except Exception as e:
                self.logger.warning(f"ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨ ({url}): {e}")
        
        # 3. ë¬¸ì„œ ë¶„í• 
        if documents:
            split_documents = self.text_splitter.split_documents(documents)
            return split_documents
        
        return []